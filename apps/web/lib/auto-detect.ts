// External library imports
import { makeGitHubRequest } from './github-auth';

// ============================================================================
// Type Definitions
// ============================================================================

interface GitHubContentsResponse {
  type: 'file' | 'dir';
  encoding?: 'base64';
  content?: string;
  name: string;
  path: string;
  sha: string;
  size: number;
  url: string;
  download_url: string | null;
}

export interface CoverageFileAttempt {
  path: string;
  success: boolean;
  error?: string;
}

interface FetchCoverageResult {
  coverageData: Record<string, unknown> | null;
  attempts: CoverageFileAttempt[];
  usedPath: string | null;
}

type SupportedFramework = 
  | "Jest"
  | "Vitest"
  | "Mocha"
  | "Jasmine"
  | "AVA"
  | "Tape"
  | "Tap"
  | "uvu"
  | "QUnit"
  | "Not Found";

interface FrameworkInfo {
  name: SupportedFramework;
  version: string | null;
  detected?: {
    name: string;
    version: string;
  };
}

// ============================================================================
// Helper Functions
// ============================================================================

/**
 * Returns array of coverage file paths to try
 * Only includes Jest's default output: coverage/coverage-final.json
 * (generated by Jest's default 'json' reporter)
 */
function getCoverageFilePaths(): string[] {
  return [
    'coverage/coverage-final.json', // Jest's default output with 'json' reporter
  ];
}

/**
 * Decode base64 content from GitHub API response
 */
function decodeBase64Content(encodedContent: string): string {
  try {
    // Remove whitespace/newlines that GitHub API may add
    const cleaned = encodedContent.replace(/\s/g, '');
    // Use Buffer in Node.js environment
    if (typeof Buffer !== 'undefined') {
      return Buffer.from(cleaned, 'base64').toString('utf-8');
    }
    // Fallback for browser environment (shouldn't happen in API route)
    return atob(cleaned);
  } catch (error) {
    throw new Error(`Failed to decode base64 content: ${error instanceof Error ? error.message : 'Unknown error'}`);
  }
}

/**
 * List directory contents from GitHub repository using Contents API
 * @param owner - Repository owner
 * @param repo - Repository name
 * @param path - Directory path in repository (empty string for root)
 * @param userId - User ID for authentication
 * @returns Array of file/directory entries, or null if not found
 */
async function listDirectoryFromGitHub(
  owner: string,
  repo: string,
  path: string,
  userId: string
): Promise<GitHubContentsResponse[] | null> {
  try {
    const url = `https://api.github.com/repos/${owner}/${repo}/contents/${encodeURIComponent(path)}`;
    const response = await makeGitHubRequest(userId, url);

    if (response.status === 404) {
      return null; // Directory not found
    }

    if (!response.ok) {
      const errorText = await response.text();
      throw new Error(`GitHub API error: ${response.status} ${response.statusText} - ${errorText}`);
    }

    const data = await response.json();

    // GitHub API returns an array for directories
    if (Array.isArray(data)) {
      return data as GitHubContentsResponse[];
    }

    // Single file response (shouldn't happen for directory listing, but handle it)
    return null;
  } catch (error) {
    console.error(`Error listing directory ${path} from GitHub:`, error);
    return null;
  }
}

/**
 * Read a file from GitHub repository using Contents API
 * @param owner - Repository owner
 * @param repo - Repository name
 * @param path - File path in repository
 * @param userId - User ID for authentication
 * @returns File content as string, or null if not found
 */
async function readFileFromGitHub(
  owner: string,
  repo: string,
  path: string,
  userId: string
): Promise<string | null> {
  try {
    const url = `https://api.github.com/repos/${owner}/${repo}/contents/${encodeURIComponent(path)}`;
    const response = await makeGitHubRequest(userId, url);

    if (response.status === 404) {
      return null; // File not found
    }

    if (!response.ok) {
      const errorText = await response.text();
      throw new Error(`GitHub API error: ${response.status} ${response.statusText} - ${errorText}`);
    }

    const data: GitHubContentsResponse = await response.json();

    // GitHub API returns base64 encoded content for files
    if (data.type !== 'file' || !data.content) {
      return null;
    }

    // Decode base64 content
    const decodedContent = decodeBase64Content(data.content);
    return decodedContent;
  } catch (error) {
    if (error instanceof Error && error.message.includes('404')) {
      return null;
    }
    throw error;
  }
}

/**
 * Validate that the parsed JSON is a valid coverage data structure
 */
function validateCoverageData(data: unknown): data is Record<string, unknown> {
  if (!data || typeof data !== 'object') {
    return false;
  }

  // Basic validation: check if it looks like coverage data
  // Coverage-final.json is an object with file paths as keys
  const entries = Object.entries(data);
  if (entries.length === 0) {
    return false;
  }

  // Check if at least one entry has coverage-like structure
  // (has properties like 's', 'b', 'f', 'l' for statements, branches, functions, lines)
  const firstEntry = entries[0];
  if (firstEntry && typeof firstEntry[1] === 'object' && firstEntry[1] !== null) {
    const fileData = firstEntry[1] as Record<string, unknown>;
    // Check for common coverage data properties
    if ('s' in fileData || 'b' in fileData || 'f' in fileData || 'l' in fileData) {
      return true;
    }
  }

  return false;
}

// ============================================================================
// Main Functions
// ============================================================================

/**
 * Fetch coverage data from repository by trying multiple common file paths
 * @param owner - Repository owner
 * @param repo - Repository name
 * @param userId - User ID for authentication
 * @returns Coverage data and metadata about attempts
 */
export async function fetchCoverageFromRepository(
  owner: string,
  repo: string,
  userId: string
): Promise<FetchCoverageResult> {
  const attempts: CoverageFileAttempt[] = [];
  const coverageFilePaths = getCoverageFilePaths();

  for (const path of coverageFilePaths) {
    try {
      const fileContent = await readFileFromGitHub(owner, repo, path, userId);

      if (fileContent === null) {
        attempts.push({
          path,
          success: false,
          error: 'File not found',
        });
        continue;
      }

      // Parse JSON
      let parsedData: unknown;
      try {
        parsedData = JSON.parse(fileContent);
      } catch (parseError) {
        attempts.push({
          path,
          success: false,
          error: `Invalid JSON: ${parseError instanceof Error ? parseError.message : 'Unknown error'}`,
        });
        continue;
      }

      // Validate coverage data structure
      if (!validateCoverageData(parsedData)) {
        attempts.push({
          path,
          success: false,
          error: 'Invalid coverage data format',
        });
        continue;
      }

      // Success! Return the data
      attempts.push({
        path,
        success: true,
      });

      return {
        coverageData: parsedData,
        attempts,
        usedPath: path,
      };
    } catch (error) {
      attempts.push({
        path,
        success: false,
        error: error instanceof Error ? error.message : 'Unknown error',
      });
      // Continue to next path
    }
  }

  // No coverage file found in any location
  return {
    coverageData: null,
    attempts,
    usedPath: null,
  };
}

/**
 * Check if repository is a monorepo (Repo Type Detection)
 * Checks package.json fields and workspace config files
 * @param packageJson - Root package.json content
 * @param owner - Repository owner (for checking config files remotely, optional)
 * @param repo - Repository name (for checking config files remotely, optional)
 * @param userId - User ID for authentication (for checking config files remotely, optional)
 * @returns Promise<boolean> - True if monorepo detected, false otherwise
 */
async function isMonorepo(
  packageJson: Record<string, unknown>,
  owner?: string,
  repo?: string,
  userId?: string
): Promise<boolean> {
  // Check package.json fields first (synchronous check)
  // Check for npm/yarn workspaces
  if (packageJson.workspaces) {
    return true;
  }

  // Check for pnpm workspaces (workspace field)
  if (packageJson.workspace) {
    return true;
  }

  // Check for lerna (common in monorepos)
  if ('lerna' in packageJson) {
    return true;
  }

  // Check for workspace config files (async check)
  // These files indicate monorepo setup even if package.json doesn't have workspace fields
  
  if (owner && repo && userId) {
    // Remote mode: check via GitHub API
    const hasPnpmWorkspace = await readFileFromGitHub(owner, repo, 'pnpm-workspace.yaml', userId);
    if (hasPnpmWorkspace !== null) {
      return true;
    }

    const hasLerna = await readFileFromGitHub(owner, repo, 'lerna.json', userId);
    if (hasLerna !== null) {
      return true;
    }

    const hasTurbo = await readFileFromGitHub(owner, repo, 'turbo.json', userId);
    if (hasTurbo !== null) {
      return true;
    }
  } else {
    // Local mode: check via filesystem
    try {
      const { existsSync } = await import('fs');
      const { join } = await import('path');
      const cwd = process.cwd();

      if (existsSync(join(cwd, 'pnpm-workspace.yaml'))) {
        return true;
      }

      if (existsSync(join(cwd, 'lerna.json'))) {
        return true;
      }

      if (existsSync(join(cwd, 'turbo.json'))) {
        return true;
      }
    } catch (error) {
      // If filesystem check fails, fall back to package.json only
      console.error('Error checking workspace config files:', error);
    }
  }

  return false;
}

// Cache for pnpm-workspace.yaml content and parsed catalogs
// Key: `${owner}/${repo}`, Value: { content: string, catalogs: Map<string, Record<string, string>> | null }
const workspaceFileCache = new Map<string, { content: string; catalogs: Map<string, Record<string, string>> | null }>();

/**
 * Get cached or read pnpm-workspace.yaml content
 * @param owner - Repository owner
 * @param repo - Repository name
 * @param userId - User ID for authentication
 * @returns File content or null if not found
 */
async function getCachedPnpmWorkspaceContent(
  owner: string,
  repo: string,
  userId: string
): Promise<string | null> {
  const cacheKey = `${owner}/${repo}`;
  
  // Check cache first
  const cached = workspaceFileCache.get(cacheKey);
  if (cached) {
    return cached.content;
  }
  
  try {
    const content = await readFileFromGitHub(owner, repo, 'pnpm-workspace.yaml', userId);
    if (!content) {
      workspaceFileCache.set(cacheKey, { content: '', catalogs: null });
      return null;
    }
    
    // Cache the content (catalogs will be parsed and cached separately when needed)
    workspaceFileCache.set(cacheKey, { content, catalogs: null });
    return content;
  } catch (error) {
    console.error('Error reading pnpm-workspace.yaml:', error);
    workspaceFileCache.set(cacheKey, { content: '', catalogs: null });
    return null;
  }
}

/**
 * Get cached or parse pnpm-workspace.yaml catalogs
 * @param owner - Repository owner
 * @param repo - Repository name
 * @param userId - User ID for authentication
 * @returns Cached catalogs or null if not found
 */
async function getCachedPnpmCatalogs(
  owner: string,
  repo: string,
  userId: string
): Promise<Map<string, Record<string, string>> | null> {
  const cacheKey = `${owner}/${repo}`;
  
  // Check cache first
  const cached = workspaceFileCache.get(cacheKey);
  if (cached && cached.catalogs !== null) {
    return cached.catalogs;
  }
  
  // Get content (from cache or read)
  const content = await getCachedPnpmWorkspaceContent(owner, repo, userId);
  if (!content) {
    return null;
  }

  // Parse catalogs section
  const catalogs = parsePnpmCatalogs(content);
  
  // Update cache with parsed catalogs
  workspaceFileCache.set(cacheKey, { content, catalogs });
  
  return catalogs;
}

/**
 * Read pnpm-workspace.yaml from repository
 * @param owner - Repository owner
 * @param repo - Repository name
 * @param userId - User ID for authentication
 * @returns Workspace patterns array or null if file doesn't exist
 * @deprecated This function is not currently used but kept for potential future use
 */
// eslint-disable-next-line @typescript-eslint/no-unused-vars
async function readPnpmWorkspaceYaml(
  owner: string,
  repo: string,
  userId: string
): Promise<string[] | null> {
  try {
    // Use cached content if available
    const content = await getCachedPnpmWorkspaceContent(owner, repo, userId);
    if (!content) {
      return null;
    }

    // Parse YAML (simple parsing for pnpm-workspace.yaml format)
    // Format is typically:
    // packages:
    //   - 'packages/*'
    //   - 'apps/*'
    const lines = content.split('\n');
    const patterns: string[] = [];
    let inPackagesSection = false;

    for (const line of lines) {
      const trimmed = line.trim();
      
      // Skip comments and empty lines
      if (!trimmed || trimmed.startsWith('#')) {
        continue;
      }

      // Check for packages: section
      if (trimmed.startsWith('packages:')) {
        inPackagesSection = true;
        continue;
      }

      // If in packages section, extract patterns
      if (inPackagesSection) {
        // Handle indented list items: - 'pattern', - "pattern", or - pattern (unquoted)
        const quotedMatch = trimmed.match(/^-\s*['"](.+?)['"]/);
        if (quotedMatch) {
          patterns.push(quotedMatch[1]);
        } else {
          // Try unquoted pattern: - pattern
          const unquotedMatch = trimmed.match(/^-\s+(.+)$/);
          if (unquotedMatch) {
            patterns.push(unquotedMatch[1].trim());
          } else if (trimmed.match(/^[a-zA-Z]/)) {
            // If we hit a new top-level key, we're done with packages
            break;
          }
        }
      }
    }

    if (patterns.length > 0) {
      console.log(`[DEBUG] Extracted patterns from pnpm-workspace.yaml: ${patterns.join(', ')}`);
    }
    return patterns.length > 0 ? patterns : null;
  } catch (error) {
    console.error('Error reading pnpm-workspace.yaml:', error);
    return null;
  }
}

/**
 * Read lerna.json from repository
 * @param owner - Repository owner
 * @param repo - Repository name
 * @param userId - User ID for authentication
 * @returns Workspace patterns array or null if file doesn't exist
 * @deprecated This function is not currently used but kept for potential future use
 */
// eslint-disable-next-line @typescript-eslint/no-unused-vars
async function readLernaJson(
  owner: string,
  repo: string,
  userId: string
): Promise<string[] | null> {
  try {
    const content = await readFileFromGitHub(owner, repo, 'lerna.json', userId);
    if (!content) {
      return null;
    }

    const lernaConfig = JSON.parse(content) as Record<string, unknown>;
    if (lernaConfig.packages && Array.isArray(lernaConfig.packages)) {
      return lernaConfig.packages as string[];
    }

    return null;
  } catch (error) {
    console.error('Error reading lerna.json:', error);
    return null;
  }
}

/**
 * Read pnpm-workspace.yaml from local file system
 * @returns Workspace patterns array or null if file doesn't exist
 * @deprecated This function is not currently used but kept for potential future use
 */
// eslint-disable-next-line @typescript-eslint/no-unused-vars
async function readPnpmWorkspaceYamlLocal(): Promise<string[] | null> {
  try {
    const { readFileSync, existsSync } = await import('fs');
    const { join } = await import('path');
    
    const workspacePath = join(process.cwd(), 'pnpm-workspace.yaml');
    if (!existsSync(workspacePath)) {
      return null;
    }

    const content = readFileSync(workspacePath, 'utf-8');
    const lines = content.split('\n');
    const patterns: string[] = [];
    let inPackagesSection = false;

    for (const line of lines) {
      const trimmed = line.trim();
      
      if (!trimmed || trimmed.startsWith('#')) {
        continue;
      }

      if (trimmed.startsWith('packages:')) {
        inPackagesSection = true;
        continue;
      }

      if (inPackagesSection) {
        // Handle indented list items: - 'pattern', - "pattern", or - pattern (unquoted)
        const quotedMatch = trimmed.match(/^-\s*['"](.+?)['"]/);
        if (quotedMatch) {
          patterns.push(quotedMatch[1]);
        } else {
          // Try unquoted pattern: - pattern
          const unquotedMatch = trimmed.match(/^-\s+(.+)$/);
          if (unquotedMatch) {
            patterns.push(unquotedMatch[1].trim());
          } else if (trimmed.match(/^[a-zA-Z]/)) {
            break;
          }
        }
      }
    }

    return patterns.length > 0 ? patterns : null;
  } catch (error) {
    console.error('Error reading pnpm-workspace.yaml (local):', error);
    return null;
  }
}

/**
 * Read lerna.json from local file system
 * @returns Workspace patterns array or null if file doesn't exist
 * @deprecated This function is not currently used but kept for potential future use
 */
// eslint-disable-next-line @typescript-eslint/no-unused-vars
async function readLernaJsonLocal(): Promise<string[] | null> {
  try {
    const { readFileSync, existsSync } = await import('fs');
    const { join } = await import('path');
    
    const lernaPath = join(process.cwd(), 'lerna.json');
    if (!existsSync(lernaPath)) {
      return null;
    }

    const content = readFileSync(lernaPath, 'utf-8');
    const lernaConfig = JSON.parse(content) as Record<string, unknown>;
    if (lernaConfig.packages && Array.isArray(lernaConfig.packages)) {
      return lernaConfig.packages as string[];
    }

    return null;
  } catch (error) {
    console.error('Error reading lerna.json (local):', error);
    return null;
  }
}


/**
 * Recursively find package.json files in a directory using GitHub directory listing
 * @param owner - Repository owner
 * @param repo - Repository name
 * @param dirPath - Directory path to search
 * @param userId - User ID for authentication
 * @param maxDepth - Maximum recursion depth (default: 3)
 * @param currentDepth - Current recursion depth
 * @returns Array of package.json file paths found
 */
async function findPackageJsonFilesInDirectory(
  owner: string,
  repo: string,
  dirPath: string,
  userId: string,
  maxDepth: number = 3,
  currentDepth: number = 0
): Promise<string[]> {
  const foundPaths: string[] = [];

  // Limit recursion depth to avoid excessive API calls
  if (currentDepth >= maxDepth) {
    return foundPaths;
  }

  try {
    const entries = await listDirectoryFromGitHub(owner, repo, dirPath, userId);
    if (!entries) {
      return foundPaths;
    }

    // Process entries in parallel where possible
    const promises: Promise<string[]>[] = [];

    for (const entry of entries) {
      // If it's a package.json file, add it
      if (entry.type === 'file' && entry.name === 'package.json') {
        const fullPath = dirPath ? `${dirPath}/package.json` : 'package.json';
        foundPaths.push(fullPath);
      }
      // If it's a directory, recurse into it
      else if (entry.type === 'dir' && currentDepth < maxDepth - 1) {
        const subDirPath = dirPath ? `${dirPath}/${entry.name}` : entry.name;
        promises.push(
          findPackageJsonFilesInDirectory(owner, repo, subDirPath, userId, maxDepth, currentDepth + 1)
        );
      }
    }

    // Wait for all recursive searches to complete
    const subResults = await Promise.all(promises);
    for (const subPaths of subResults) {
      foundPaths.push(...subPaths);
    }
  } catch (error) {
    console.error(`Error searching directory ${dirPath}:`, error);
  }

  return foundPaths;
}

/**
 * Find all package.json files in a monorepo
 * Uses GitHub directory listing API for efficient discovery
 * @param owner - Repository owner
 * @param repo - Repository name
 * @param userId - User ID for authentication
 * @param workspacePatterns - Workspace patterns from root package.json (unused but kept for compatibility)
 * @returns Array of package.json file paths found
 */
async function findMonorepoPackageJsonFiles(
  owner: string,
  repo: string,
  userId: string,
  workspacePatterns: string[]
): Promise<string[]> {
  const foundPaths: string[] = [];
  
  // Always include root
  foundPaths.push('package.json');

  // Common monorepo directory names (limited to most common)
  const commonMonorepoDirs = ['apps', 'packages'];

  // Extract base directories from workspace patterns if provided
  const patternDirs = new Set<string>();
  for (const pattern of workspacePatterns) {
    // Handle recursive patterns like "packages/**"
    if (pattern.includes('**')) {
      const baseDir = pattern.split('**')[0].replace(/\/$/, '');
      if (baseDir) {
        patternDirs.add(baseDir);
      }
    } else {
      // Extract directory from patterns like "apps/*", "packages/*"
      const parts = pattern.split('/');
      if (parts.length >= 1 && parts[0] !== '*') {
        patternDirs.add(parts[0]);
      }
    }
  }

  // Use pattern directories if available, otherwise use common directories
  const dirsToCheck = patternDirs.size > 0 
    ? Array.from(patternDirs) 
    : commonMonorepoDirs;

  console.log(`[Framework Detection] Searching for package.json files in directories: ${dirsToCheck.join(', ')}`);

  // Search each directory in parallel
  const searchPromises = dirsToCheck.map(dir => 
    findPackageJsonFilesInDirectory(owner, repo, dir, userId, 3, 0)
  );

  const results = await Promise.all(searchPromises);
  for (const paths of results) {
    foundPaths.push(...paths);
  }

  // Remove duplicates
  const uniquePaths = Array.from(new Set(foundPaths));
  console.log(`[Framework Detection] Found ${uniquePaths.length} package.json files: ${uniquePaths.join(', ')}`);
  
  return uniquePaths;
}

/**
 * Read package.json from GitHub repository
 * @param owner - Repository owner
 * @param repo - Repository name
 * @param userId - User ID for authentication
 * @returns Parsed package.json content, or null if not found
 */
export async function readPackageJsonFromRepository(
  owner: string,
  repo: string,
  userId: string
): Promise<Record<string, unknown> | null> {
  try {
    const content = await readFileFromGitHub(owner, repo, 'package.json', userId);
    if (!content) {
      return null;
    }

    const parsed = JSON.parse(content);
    return parsed as Record<string, unknown>;
  } catch (error) {
    console.error('Error reading package.json from repository:', error);
    return null;
  }
}

/**
 * Parse catalogs section from pnpm-workspace.yaml content
 * @param content - Full content of pnpm-workspace.yaml file
 * @returns Map of catalog name to package versions, or null if no catalogs found
 */
function parsePnpmCatalogs(content: string): Map<string, Record<string, string>> | null {
  const catalogs = new Map<string, Record<string, string>>();
  const lines = content.split('\n');
  let inCatalogsSection = false;
  let currentCatalog: string | null = null;
  let indentLevel = 0;

  for (let i = 0; i < lines.length; i++) {
    const line = lines[i];
    const trimmed = line.trim();
    
    // Skip comments and empty lines
    if (!trimmed || trimmed.startsWith('#')) {
      continue;
    }

    // Check for catalogs: section
    if (trimmed.startsWith('catalogs:')) {
      inCatalogsSection = true;
      indentLevel = line.match(/^(\s*)/)?.[1].length || 0;
      continue;
    }

    if (inCatalogsSection) {
      const currentIndent = line.match(/^(\s*)/)?.[1].length || 0;
      
      // If we've gone back to root level or higher, we're done with catalogs
      if (currentIndent <= indentLevel && trimmed.match(/^[a-zA-Z]/)) {
        break;
      }

      // Check for catalog name (e.g., "e2e:")
      const catalogMatch = trimmed.match(/^([a-zA-Z0-9_-]+):\s*$/);
      if (catalogMatch) {
        currentCatalog = catalogMatch[1];
        catalogs.set(currentCatalog, {});
        continue;
      }

      // Check for package version entries (e.g., "playwright: ^1.57.0" or "'@playwright/test': ^1.57.0")
      if (currentCatalog) {
        const packageMatch = trimmed.match(/^(['"]?)([^'":\s]+)\1:\s*(.+)$/);
        if (packageMatch) {
          const packageName = packageMatch[2].replace(/^['"]|['"]$/g, '');
          const version = packageMatch[3].trim();
          const catalog = catalogs.get(currentCatalog);
          if (catalog) {
            catalog[packageName] = version;
          }
        }
      }
    }
  }

  return catalogs.size > 0 ? catalogs : null;
}

/**
 * Resolve catalog reference to actual version
 * @param catalogRef - Catalog reference like "catalog:e2e"
 * @param packageName - Package name to look up (e.g., "@playwright/test")
 * @param owner - Repository owner (for reading workspace file)
 * @param repo - Repository name (for reading workspace file)
 * @param userId - User ID for authentication
 * @returns Resolved version or null if not found
 */
async function resolveCatalogVersion(
  catalogRef: string,
  packageName: string,
  owner: string,
  repo: string,
  userId: string
): Promise<string | null> {
  // Extract catalog name from reference (e.g., "catalog:e2e" -> "e2e")
  const catalogName = catalogRef.replace(/^catalog:/, '');
  
  try {
    // Get cached catalogs (or read and cache)
    const catalogs = await getCachedPnpmCatalogs(owner, repo, userId);
    if (!catalogs) {
      return null;
    }

    // Get the catalog
    const catalog = catalogs.get(catalogName);
    if (!catalog) {
      return null;
    }

    // Look up package version (try exact match first, then case-insensitive)
    const version = catalog[packageName] || 
                    Object.entries(catalog).find(([key]) => 
                      key.toLowerCase() === packageName.toLowerCase()
                    )?.[1];

    if (version) {
      // Remove version prefix (^, ~) if present
      return version.replace(/^[\^~]/, '');
    }

    return null;
  } catch (error) {
    console.error(`[E2E Detection] Error resolving catalog version for ${catalogRef}:`, error);
    return null;
  }
}

/**
 * Extract version from a dependency version string
 * Handles catalog references (catalog:*), workspace references (workspace:*), and standard versions
 * @param versionString - Version string from package.json
 * @param packageName - Package name (for catalog resolution)
 * @param owner - Repository owner (for catalog resolution, optional)
 * @param repo - Repository name (for catalog resolution, optional)
 * @param userId - User ID (for catalog resolution, optional)
 * @returns Extracted version or null if it's a reference (catalog/workspace)
 */
async function extractVersion(
  versionString: string,
  packageName?: string,
  owner?: string,
  repo?: string,
  userId?: string
): Promise<string | null> {
  // Handle catalog references (pnpm): "catalog:e2e", "catalog:react19"
  if (versionString.startsWith('catalog:')) {
    // Try to resolve from pnpm-workspace.yaml catalogs
    if (packageName && owner && repo && userId) {
      const resolved = await resolveCatalogVersion(versionString, packageName, owner, repo, userId);
      if (resolved) {
        console.log(`[Framework Detection] Resolved catalog ${versionString} for ${packageName} to version ${resolved}`);
        return resolved;
      }
    }
    return null; // Catalog references don't have versions in package.json
  }
  
  // Handle workspace references: "workspace:*", "workspace:^1.0.0"
  if (versionString.startsWith('workspace:')) {
    return null; // Workspace references don't have versions in package.json
  }
  
  // Handle file/protocol references: "file:../packages/foo", "git+https://..."
  if (versionString.startsWith('file:') || versionString.startsWith('git+') || versionString.startsWith('http')) {
    return null;
  }
  
  // Handle standard versions: remove ^ and ~ prefixes
  return versionString.replace(/^[\^~]/, '');
}

/**
 * Detect framework from local file system (for development/testing)
 * Checks root package.json and monorepo workspace package.json files
 * @returns Framework info detected from local package.json files
 */
export async function detectFrameworkFromLocal(): Promise<FrameworkInfo> {
  try {
    const { readFileSync, existsSync } = await import('fs');
    const { join } = await import('path');
    
    // Read root package.json
    const rootPackageJsonPath = join(process.cwd(), 'package.json');
    
    if (!existsSync(rootPackageJsonPath)) {
      return {
        name: "Not Found",
        version: null,
      };
    }

    const rootPackageJson = JSON.parse(readFileSync(rootPackageJsonPath, 'utf-8')) as Record<string, unknown>;
    
    // Check if it's a monorepo (local mode - no owner/repo/userId)
    const isMonorepoRepo = await isMonorepo(rootPackageJson);
    
    // Check root package.json for framework
    // Note: For local detection, we don't have owner/repo/userId, so catalog resolution won't work
    const rootFramework = await detectFrameworkFromPackageJson(rootPackageJson);
    
    // If not a monorepo, return root result
    if (!isMonorepoRepo) {
      return rootFramework;
    }

    // It's a monorepo - check workspace package.json files
    // Use common monorepo directory names (simplified - no pattern extraction needed)
    const commonMonorepoDirs = ['apps', 'packages', 'libs', 'modules', 'services', 'workspaces'];
    const commonSubdirs = ['web', 'api', 'frontend', 'backend', 'server', 'client', 'shared', 'common', 'admin', 'dashboard', 'mobile', 'desktop'];
    
    const dirsToCheck = commonMonorepoDirs;
    
    // Check each directory for package.json files
    for (const dir of dirsToCheck) {
      for (const subdir of commonSubdirs) {
        const path = join(process.cwd(), dir, subdir, 'package.json');
        if (existsSync(path)) {
          try {
            const packageJson = JSON.parse(readFileSync(path, 'utf-8')) as Record<string, unknown>;
            // Note: For local detection, we don't have owner/repo/userId, so catalog resolution won't work
            const framework = await detectFrameworkFromPackageJson(packageJson);
            
            // If we find any supported framework, return immediately
            if (framework.name !== "Not Found") {
              return framework;
            }
          } catch (error) {
            // Continue to next package.json if this one fails
            console.error(`Error reading ${path}:`, error);
          }
        }
      }
    }

    // Return root result if no workspace package.json had a framework
    return rootFramework;
  } catch (error) {
    console.error('Error detecting framework from local:', error);
    return {
      name: "Not Found",
      version: null,
    };
  }
}

/**
 * Read all package.json files from a monorepo and detect test framework
 * Checks root package.json first, then workspace package.json files
 * @param owner - Repository owner
 * @param repo - Repository name
 * @param userId - User ID for authentication
 * @returns Framework info detected from any package.json in the monorepo
 */
export async function detectFrameworkFromMonorepo(
  owner: string,
  repo: string,
  userId: string
): Promise<FrameworkInfo> {
  try {
    // Read root package.json first
    const rootPackageJson = await readPackageJsonFromRepository(owner, repo, userId);
    
    if (!rootPackageJson) {
      return {
        name: "Not Found",
        version: null,
      };
    }
    
    // Check root package.json for framework FIRST (before checking if monorepo)
    // This optimizes the common case where framework is in root
    const rootFramework = await detectFrameworkFromPackageJson(rootPackageJson, owner, repo, userId);
    
    // Return immediately if we found a supported framework (not "Not Found")
    if (rootFramework.name !== "Not Found") {
      return rootFramework;
    }

    // Check if it's a monorepo (checks both package.json fields AND workspace config files)
    // Some repos (like pnpm) only define workspaces in pnpm-workspace.yaml, not in package.json
    const isMonorepoRepo = await isMonorepo(rootPackageJson, owner, repo, userId);
    console.log(`[Framework Detection] Is monorepo: ${isMonorepoRepo}`);
    
    // If not a monorepo, return root result
    if (!isMonorepoRepo) {
      console.log(`[Framework Detection] Not a monorepo, returning root result`);
      return rootFramework;
    }

    // It's a monorepo - check workspace package.json files
    console.log(`[Framework Detection] Detected as monorepo, finding package.json files...`);
    let packageJsonPaths: string[];
    try {
      packageJsonPaths = await findMonorepoPackageJsonFiles(owner, repo, userId, []);
    } catch (error) {
      console.error(`[Framework Detection] Error finding package.json files:`, error);
      if (error instanceof Error) {
        console.error(`[Framework Detection] Error stack:`, error.stack);
      }
      // Return root result if we can't find workspace files
      return rootFramework;
    }

    // Check each package.json file found
    for (const path of packageJsonPaths) {
      if (path === 'package.json') {
        continue; // Already checked root
      }

      try {
        const content = await readFileFromGitHub(owner, repo, path, userId);
        if (content) {
          const packageJson = JSON.parse(content) as Record<string, unknown>;
          const framework = await detectFrameworkFromPackageJson(packageJson, owner, repo, userId);
          
          // If we find any supported framework, return immediately
          if (framework.name !== "Not Found") {
            return framework;
          }
        }
      } catch (error) {
        // Continue to next package.json if this one fails
        console.error(`Error reading ${path}:`, error);
      }
    }

    // Return root result if no workspace package.json had a framework
    return rootFramework;
  } catch (error) {
    console.error('Error detecting framework from monorepo:', error);
    return {
      name: "Not Found",
      version: null,
    };
  }
}

/**
 * Supported unit testing frameworks with their package names and display names
 * Ordered by popularity (Jest first as it's our primary supported framework)
 */
const SUPPORTED_FRAMEWORKS: Array<{
  packageName: string;
  displayName: SupportedFramework;
}> = [
  { packageName: 'jest', displayName: 'Jest' },
  { packageName: 'vitest', displayName: 'Vitest' },
  { packageName: 'mocha', displayName: 'Mocha' },
  { packageName: 'jasmine', displayName: 'Jasmine' },
  { packageName: 'ava', displayName: 'AVA' },
  { packageName: 'tape', displayName: 'Tape' },
  { packageName: 'tap', displayName: 'Tap' },
  { packageName: 'uvu', displayName: 'uvu' },
  { packageName: 'qunit', displayName: 'QUnit' },
];

/**
 * Detect test framework from a single package.json
 * Checks all supported frameworks in priority order
 * @param packageJson - Parsed package.json content
 * @param owner - Repository owner (for catalog resolution, optional)
 * @param repo - Repository name (for catalog resolution, optional)
 * @param userId - User ID (for catalog resolution, optional)
 * @returns Framework info
 */
async function detectFrameworkFromPackageJson(
  packageJson: Record<string, unknown>,
  owner?: string,
  repo?: string,
  userId?: string
): Promise<FrameworkInfo> {
  const allDependencies = {
    ...(packageJson.dependencies as Record<string, string> || {}),
    ...(packageJson.devDependencies as Record<string, string> || {}),
  };

  // Check for Jest first (primary supported framework)
  if (allDependencies.jest) {
    const versionString = allDependencies.jest;
    const version = await extractVersion(versionString, 'jest', owner, repo, userId);
    return {
      name: 'Jest',
      version,
    };
  }

  // Check supported frameworks in order (already prioritized in array definition)
  for (const framework of SUPPORTED_FRAMEWORKS) {
    if (allDependencies[framework.packageName]) {
      const versionString = allDependencies[framework.packageName];
      const version = await extractVersion(versionString, framework.packageName, owner, repo, userId);
      return {
        name: framework.displayName,
        version,
      };
    }
  }

  // No framework detected
  return {
    name: "Not Found",
    version: null,
  };
}

